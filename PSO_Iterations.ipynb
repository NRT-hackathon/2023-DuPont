{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f09cdb6e",
   "metadata": {},
   "source": [
    "### DuPont Mixture Design - Inverse Modeling\n",
    "\n",
    "## Alison Shapiro, Sean Farrington, and Peter Osazuwa\n",
    "\n",
    "***Machine Learning Techniques Used:*** \n",
    "\n",
    "Linear Regression\n",
    "\n",
    "Gaussian Process Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecba6cd2",
   "metadata": {},
   "source": [
    "## Script for Particle Swarm Optimization\n",
    "\n",
    "#### Utilize predictions from the Gaussian process regression\n",
    "\n",
    "Start by remaking the Gaussian process regression code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf080d15",
   "metadata": {},
   "source": [
    "# Gaussian Process Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e810d8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd180414",
   "metadata": {},
   "source": [
    "### Import new packages for GPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebbf62cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel as C, RBF, WhiteKernel\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape, r2_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae8c777",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a86c866",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'DATA/training_inputs.xlsx'\n",
    "\n",
    "df = pd.read_excel(file)\n",
    "\n",
    "design = ['Powdered Additive','Base Resin A','Base Resin B','Stabilizer','Temperature','Screw Speed (RPM)']\n",
    "performance = ['Toughness (J/m2)','Modulus (GPa)']\n",
    "\n",
    "X = df[design]\n",
    "y = df[performance]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(data=X,\n",
    "                columns=design)\n",
    "# print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7e5894",
   "metadata": {},
   "source": [
    "### Create model \n",
    "\n",
    "***Need two separate models for each output***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02b7419b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = C() + RBF(length_scale=np.ones(X.shape[1]))\n",
    "\n",
    "# Split to two models\n",
    "reg_0 = GaussianProcessRegressor(kernel=kernel,random_state=1773).fit(X,y[performance[0]])\n",
    "reg_1 = GaussianProcessRegressor(kernel=kernel,random_state=1773).fit(X,y[performance[1]])\n",
    "\n",
    "y_pred_0 = reg_0.predict(X)\n",
    "y_pred_1 = reg_1.predict(X)\n",
    "y_pred_GPR = pd.DataFrame({performance[0]:y_pred_0,\n",
    "                       performance[1]:y_pred_1\n",
    "                       })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a44fcd0",
   "metadata": {},
   "source": [
    "# Particle Swarm Routine\n",
    "\n",
    "In this inverse model we will try to predict a data point from the testing set\n",
    "\n",
    "The values for this datum is as follows:\n",
    "\n",
    "- Powdered Additive: 0.32\n",
    "- Base Resin A: 0.6\n",
    "- Base Resin B: 0.05\n",
    "- Stabilizer: 0.09\n",
    "- Temperature: 406\n",
    "- Screw Speed (RPM): 120\n",
    "\n",
    "\n",
    "- Toughness (J/m2): 656\n",
    "- Modulus (GPa): 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15ef8a2f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pyswarms as ps\n",
    "from pyswarms.utils.plotters import (plot_cost_history, plot_contour, plot_surface)\n",
    "\n",
    "X_true = np.array([0.32,0.6,0.05,0.09,406,120])\n",
    "y_true = np.array([656,5.1])\n",
    "\n",
    "def CostFuncSlack(x,a,b):\n",
    "    \"\"\"\n",
    "    Input 'x' is an array of unscaled variables. For this function they are:\n",
    "    \n",
    "    x = ['Powdered Additive','Base Resin A','Base Resin B','Temperature','Screw Speed']\n",
    "    \n",
    "    Notice that 'Stabilizer' is removed from this array, this must be accounted for so \n",
    "    scaling is done properly.\n",
    "    \n",
    "    Use 'y_0_target' and 'y_1_target' to assign the desired performance\n",
    "    \n",
    "    The cost function uses the slack variable approach to reduce\n",
    "    dimensionality and ensure the composition is real.\n",
    "    \n",
    "    The barrier term here is a large penalty associated with the first three components \n",
    "    being greater than or equal to 1\n",
    "    \n",
    "    \"\"\"\n",
    "    y_0_target = a # Target toughness (J/m2)\n",
    "    y_1_target = b # Target Modulus (GPa)\n",
    "    \n",
    "    sum_noslack = x[:,0]+x[:,1]+x[:,2]\n",
    "    \n",
    "    slack = 1 - (sum_noslack)\n",
    "    \n",
    "    x_full = np.insert(x,3,slack,axis=1) # Insert in the fourth column of the array\n",
    "    \n",
    "    x_scaled = scaler.transform(x_full)\n",
    "    \n",
    "    y_0,std_0 = reg_0.predict(x_scaled,return_std=True)\n",
    "    y_1,std_1 = reg_1.predict(x_scaled,return_std=True)\n",
    "    \n",
    "    var_0 = std_0**2/y_0_target # Variance normalized by the target value\n",
    "    var_1 = std_1**2/y_1_target # Variance normalized by the target value\n",
    "    \n",
    "    y_0_penalty = ((y_0-y_0_target)/y_0_target)**2\n",
    "    y_1_penalty = ((y_1-y_1_target)/y_1_target)**2\n",
    "    \n",
    "    barrier = np.zeros(len(x_full[:,0]))\n",
    "    \n",
    "    for i in range(len(x_full[:,0])):\n",
    "        if sum_noslack[i] >= 1:\n",
    "            barrier[i] = 1e6\n",
    "            \n",
    "    loss = y_0_penalty + y_1_penalty + var_0 + var_1 + barrier\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e895ff33",
   "metadata": {},
   "source": [
    "# Particle swarm with 10 iterations for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d467b9e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-02 15:17:18,421 - pyswarms.single.global_best - INFO - Optimize for 10000 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
      "pyswarms.single.global_best: 100%|████████████████|10000/10000, best_cost=0.000631\n",
      "2023-05-02 15:17:30,326 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.0006313222391285296, best pos: [2.85815927e-01 2.72003588e-01 3.63873160e-01 4.23774421e+02\n",
      " 9.61021154e+01]\n",
      "2023-05-02 15:17:30,352 - pyswarms.single.global_best - INFO - Optimize for 10000 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
      "pyswarms.single.global_best: 100%|████████████████|10000/10000, best_cost=0.000626\n",
      "2023-05-02 15:17:42,366 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.0006261677148739633, best pos: [2.85618089e-01 2.72004377e-01 3.63872672e-01 4.23774675e+02\n",
      " 9.61605148e+01]\n",
      "2023-05-02 15:17:42,401 - pyswarms.single.global_best - INFO - Optimize for 10000 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
      "pyswarms.single.global_best:  92%|███████████████▋ |9231/10000, best_cost=0.000625IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "pyswarms.single.global_best: 100%|████████████████|10000/10000, best_cost=0.000625\n",
      "2023-05-02 15:17:54,675 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.0006245866941716575, best pos: [2.85311136e-01 2.72448946e-01 3.63872745e-01 4.23774673e+02\n",
      " 9.61606537e+01]\n",
      "2023-05-02 15:17:54,710 - pyswarms.single.global_best - INFO - Optimize for 10000 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
      "pyswarms.single.global_best: 100%|████████████████|10000/10000, best_cost=0.000625\n",
      "2023-05-02 15:18:06,129 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.0006245866941710532, best pos: [2.85311136e-01 2.72448946e-01 3.63872745e-01 4.23774673e+02\n",
      " 9.61606537e+01]\n",
      "2023-05-02 15:18:06,170 - pyswarms.single.global_best - INFO - Optimize for 10000 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
      "pyswarms.single.global_best: 100%|████████████████|10000/10000, best_cost=0.000625\n",
      "2023-05-02 15:18:17,605 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.0006245866941710532, best pos: [2.85311136e-01 2.72448946e-01 3.63872745e-01 4.23774673e+02\n",
      " 9.61606537e+01]\n",
      "2023-05-02 15:18:17,654 - pyswarms.single.global_best - INFO - Optimize for 10000 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
      "pyswarms.single.global_best: 100%|████████████████|10000/10000, best_cost=0.000625\n",
      "2023-05-02 15:18:29,386 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.0006245866941710532, best pos: [2.85311136e-01 2.72448946e-01 3.63872745e-01 4.23774673e+02\n",
      " 9.61606537e+01]\n",
      "2023-05-02 15:18:29,425 - pyswarms.single.global_best - INFO - Optimize for 10000 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
      "pyswarms.single.global_best: 100%|████████████████|10000/10000, best_cost=0.000625\n",
      "2023-05-02 15:18:41,116 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.0006245866941710532, best pos: [2.85311136e-01 2.72448946e-01 3.63872745e-01 4.23774673e+02\n",
      " 9.61606537e+01]\n",
      "2023-05-02 15:18:41,161 - pyswarms.single.global_best - INFO - Optimize for 10000 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
      "pyswarms.single.global_best: 100%|████████████████|10000/10000, best_cost=0.000625\n",
      "2023-05-02 15:18:52,842 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.0006245866941710532, best pos: [2.85311136e-01 2.72448946e-01 3.63872745e-01 4.23774673e+02\n",
      " 9.61606537e+01]\n",
      "2023-05-02 15:18:52,878 - pyswarms.single.global_best - INFO - Optimize for 10000 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
      "pyswarms.single.global_best: 100%|████████████████|10000/10000, best_cost=0.000625\n",
      "2023-05-02 15:19:04,910 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.0006245866941710532, best pos: [2.85311136e-01 2.72448946e-01 3.63872745e-01 4.23774673e+02\n",
      " 9.61606537e+01]\n",
      "2023-05-02 15:19:04,942 - pyswarms.single.global_best - INFO - Optimize for 10000 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
      "pyswarms.single.global_best: 100%|████████████████|10000/10000, best_cost=0.000625\n",
      "2023-05-02 15:19:17,599 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.0006245866941710532, best pos: [2.85311136e-01 2.72448946e-01 3.63872745e-01 4.23774673e+02\n",
      " 9.61606537e+01]\n"
     ]
    }
   ],
   "source": [
    "# Make this method loop and produce 10 results to compare in a table\n",
    "# Create empty Excel file\n",
    "file = 'ANALYSIS/Iterations_PSO.xlsx'\n",
    "df = pd.DataFrame()\n",
    "df.to_excel(file)\n",
    "\n",
    "# Set-up hyperparameters\n",
    "options = {'c1': 0.5, 'c2': 0.3, 'w':0.9}\n",
    "max_bound = np.array([1,1,1,475,121])\n",
    "min_bound = np.array([0,0,0,380,79])\n",
    "bounds = (min_bound,max_bound)\n",
    "\n",
    "# Call instance of PSO\n",
    "optimizer = ps.single.GlobalBestPSO(n_particles=10, dimensions=len(X.columns)-1, options=options, bounds=bounds)\n",
    "\n",
    "# Iterate the optimizer 10 times to observe repeatability\n",
    "for i in range(10):\n",
    "    # Perform optimization\n",
    "    cost, pos = optimizer.optimize(CostFuncSlack, iters=10_000, a = y_true[0], b = y_true[1])\n",
    "\n",
    "    Stabilizer = 1 - (pos[0]+pos[1]+pos[2])\n",
    "\n",
    "    pos = np.insert(pos,3,Stabilizer)\n",
    "\n",
    "    pos_scaled = scaler.transform(pos.reshape(1,-1))\n",
    "    y_pred_0 = reg_0.predict(pos_scaled)\n",
    "    y_pred_1 = reg_1.predict(pos_scaled)\n",
    "\n",
    "    df1 = pd.read_excel(file)\n",
    "    df2 = pd.DataFrame({'Cost':cost,\n",
    "                        design[0]:pos[0],\n",
    "                        design[1]:pos[1],\n",
    "                        design[2]:pos[2],\n",
    "                        design[3]:pos[3],\n",
    "                        design[4]:pos[4],\n",
    "                        design[5]:pos[5],\n",
    "                        performance[0]:y_pred_0,\n",
    "                        performance[1]:y_pred_1\n",
    "                        })\n",
    "    df = pd.concat([df1,df2])\n",
    "\n",
    "    df.to_excel(file,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
